import matplotlib as mpl
import numpy as np
import pandas as pd
from sklearn.datasets import load_iris
import matplotlib.pyplot as plt
#读取鸢尾花数据集
iris = load_iris()
data = pd.DataFrame(iris.data, columns=iris.feature_names)
data['label'] = iris.target
data.columns = ['sepal length','sepal width','petal length','petal width','label']
#看是否有重复的记录
print(data.duplicated().any())
data.drop_duplicates(inplace=True)
#查看各个类别的鸢尾花具有多少条记录
print(data['label'].value_counts())
data_regression = data.drop(['label'], axis=1)
class KNN:
    """使用Python语言实现K近邻算法的分类"""
    def __init__(self, k):
        """初始化方法
        :parameters
        ----
        k:int
        邻居的个数
        """
        self.k = k
    def fit(self, X, y):
        """训练方法
        :param X: 类数组类型，形状为：[样本数量，特征数量]
        待训练的样本特征（属性）
        :param y: 类数组类型 形状为：[样本数量]
        每个样本的目标值
        """
        #将X、y转换为ndarray数组类型，加强数据的兼容性
        self.X = np.asarray(X)
        self.y = np.asarray(y)
    def predict(self, X):
        """根据参数传递的样本，对样本数据进行预测
        :param X: 类数组类型，形状为：[样本数量，特征数量]
        待训练的样本特征（属性）
        :return:数组类型
        预测结果
        """
        X = np.asarray(X)
        result = []
        #对ndarray数组进行遍历，每次取出数组中的一行数据
        for x in X:
            #对于测试集中的每一个样本，依次与训练集中的所有样本求距离
            dis = np.sqrt(np.sum((x-self.X)**2, axis=1))
            #返回数组排序后，每个元素在原数组（排序之前的数组）中的索引
            index = dis.argsort()
            #进行截断，只取前K个元素[取距离最近的K个元素的索引]
            index = index[:self.k]
            #返回数组中每个元素出现的次数，元素必须是非负的整数
            count = np.bincount(self.y[index])
            #返回ndarray数组中，值最大的元素对应的索引，该索引就是我们判定的类别
            result.append(count.argmax())
        return np.asarray(result)
    def predict2(self, X):
        """根据参数传递的样本，对样本数据进行预测（考虑权重）
        :param X: 类数组类型，形状为：[样本数量，特征数量]
        待训练的样本特征（属性）
        :return:数组类型
        预测结果
        """
        X = np.asarray(X)
        result = []
        # 对ndarray数组进行遍历，每次取出数组中的一行数据
        for x in X:
            # 对于测试集中的每一个样本，依次与训练集中的所有样本求距离
            dis = np.sqrt(np.sum((x - self.X) ** 2, axis=1))
            # 返回数组排序后，每个元素在原数组（排序之前的数组）中的索引
            index = dis.argsort()
            # 进行截断，只取前K个元素[取距离最近的K个元素的索引]
            index = index[:self.k]
            # 返回数组中每个元素出现的次数，元素必须是非负的整数[考虑weights为权重，以距离的倒数为权重］
            count = np.bincount(self.y[index],weights=1/(dis[index]+1e-6))
            # 返回ndarray数组中，值最大的元素对应的索引，该索引就是我们判定的类别
            result.append(count.argmax())
        return np.asarray(result)
    def fit_regression(self, X, y):
        '''使用Python语言实现K近邻算法的回归
        根据前三个特征值，预测出第四个特征值
        训练方法
        param X:  类数组类型，形状为：[样本数量，特征数量]
        待训练的样本特征（属性）
        :param y: 类数组类型 形状为：[样本数量]
        每个样本的目标值
        '''
        self.X = np.asarray(X)
        self.y = np.asarray(y)
    def predict_regression(self, X):
        '''根据参数传递的样本，对样本数据进行预测
        :param X: 类数组类型，形状为：[样本数量，特征数量]
        待训练的样本特征（属性）
        :return:数组类型
        预测结果
        '''
        X = np.asarray(X)
        result = []
        for x in X:
            dis = np.sqrt(np.sum((x - self.X)**2, axis=1))
            index = dis.argsort()
            index = index[:self.k]
            result.append(np.mean(self.y[index]))
        return np.asarray(result)
    def predict_regression2(self, X):
        '''根据参数传递的样本，对样本数据进行预测（考虑权重）
        :param X: 类数组类型，形状为：[样本数量，特征数量]
        待训练的样本特征（属性）
        :return:数组类型
        预测结果
        '''
        X = np.asarray(X)
        result = []
        for x in X:
            dis = np.sqrt(np.sum((x - self.X)**2, axis=1))
            index = dis.argsort()
            index = index[:self.k]
            #所有节点距离的倒数之和
            s = np.sum(1/(dis[index]+1e-6))
            weight = (1/(dis[index]+1e-6))/s
            result.append(np.sum(weight*self.y[index]))
        return np.asarray(result)

#提取出每个类别的鸢尾花数据
t0 = data[data['label']==0]
t1 = data[data['label']==1]
t2 = data[data['label']==2]
#将数据随机打乱
t0 = t0.sample(len(t0), random_state=0)
t1 = t1.sample(len(t1), random_state=0)
t2 = t2.sample(len(t2), random_state=0)
#构建训练集与测试集
train_X = pd.concat([t0.iloc[:40,:-1], t1.iloc[:40,:-1], t2.iloc[:40,:-1]], axis=0)
train_y = pd.concat([t0.iloc[:40,-1], t1.iloc[:40,-1], t2.iloc[:40,-1]], axis=0)
test_X = pd.concat([t0.iloc[40:,:-1], t1.iloc[40:,:-1], t2.iloc[:40,:-1]], axis=0)
test_y = pd.concat([t0.iloc[40:,-1], t1.iloc[40:,-1], t2.iloc[:40,-1]], axis=0)
#创建KNN对象，进行训练与测试
knn = KNN(k=5)
#进行训练
knn.fit(train_X, train_y)
#进行测试，获得训练的结果
result = knn.predict(test_X)
result2 = knn.predict2(test_X)
#默认情况下，matplotlib不支持中文显示，我们需进行一下设置
mpl.rcParams['font.family'] = 'SimHei'
mpl.rcParams['axes.unicode_minus'] = False
#绘制训练集数据
plt.scatter(x=t0['sepal length'][:40],y=t0['petal length'][:40],color='r',label='0')
plt.scatter(x=t1['sepal length'][:40],y=t1['petal length'][:40],color='b',label='1')
plt.scatter(x=t2['sepal length'][:40],y=t2['petal length'][:40],color='g',label='2')
plt.legend()
plt.title('train')
#绘制测试集数据
right = test_X[result == test_y]
wrong = test_X[result != test_y]
plt.scatter(x = right['sepal length'],y = right['petal length'],color='c',marker='x',label='right')
plt.scatter(x = wrong['sepal length'],y = wrong['petal length'],color='m',marker='>',label='wrong')
plt.legend()
plt.title('predict')
plt.show()
print('predict',len(wrong))
#绘制训练集数据
plt.scatter(x=t0['sepal length'][:40],y=t0['petal length'][:40],color='r',label='0')
plt.scatter(x=t1['sepal length'][:40],y=t1['petal length'][:40],color='b',label='1')
plt.scatter(x=t2['sepal length'][:40],y=t2['petal length'][:40],color='g',label='2')
plt.legend()
plt.title('train')
#绘制测试集数据
right2 = test_X[result2 == test_y]
wrong2 = test_X[result2 != test_y]
plt.scatter(x = right2['sepal length'],y = right2['petal length'],color='c',marker='x',label='right2')
plt.scatter(x = wrong2['sepal length'],y = wrong2['petal length'],color='m',marker='>',label='wrong2')
plt.legend()
plt.title('predict2')
plt.show()
print('predict2',len(wrong2))
t_regression = data_regression.sample(len(data_regression), random_state=0)
train_X_regression = data_regression.iloc[:120,:-1]
train_y_regression = data_regression.iloc[:120,-1]
test_X_regression = data_regression.iloc[120:,:-1]
test_y_regression = data_regression.iloc[120:,-1]
knn.fit_regression(train_X_regression, train_y_regression)
result_regression = knn.predict_regression(test_X_regression)
#绘制预测值
plt.plot(result_regression,'ro-',label='预测值')
#绘制真实值
plt.plot(test_y_regression.values,'go--',label='真实值')
plt.title('regression')
plt.legend()
plt.show()
result_regression2 = knn.predict_regression2(test_X_regression)
#绘制预测值
plt.plot(result_regression2,'ro-',label='预测值')
#绘制真实值
plt.plot(test_y_regression.values,'go--',label='真实值')
plt.title('regression2')
plt.legend()
plt.show()
